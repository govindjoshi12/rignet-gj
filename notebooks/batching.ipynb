{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f203c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../utils')\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_scatter import scatter_max\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0f0f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n",
      "torch.Size([20, 3])\n"
     ]
    }
   ],
   "source": [
    "nums = torch.tensor([10, 20])\n",
    "graphs = [torch.zeros(n, 3) for n in nums]\n",
    "for g in graphs:\n",
    "    print(g.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce10fd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = torch.concat(graphs)\n",
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ffa2a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor([i for i, num in enumerate(nums) for _ in range(num)])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be11d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/4m68bwzs6x14fjh__wpb9t180000gn/T/ipykernel_18220/4148335854.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = idxs.repeat_interleave(torch.tensor(nums))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faster with repeat_interleave\n",
    "idxs = torch.arange(len(nums))\n",
    "indices = idxs.repeat_interleave(torch.tensor(nums))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d81701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 4, 9, 7, 3, 2, 9, 8, 0, 1],\n",
       "        [9, 4, 2, 3, 1, 4, 7, 4, 5, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(low=0, high=10, size=(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28b2c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[6, 2, 2, 9, 5, 5, 8, 6, 5, 2],\n",
       "         [5, 2, 7, 7, 9, 4, 8, 8, 4, 1]]),\n",
       " tensor([[11, 12, 22, 23, 13, 14, 10, 17, 26, 25, 24, 20, 24, 19, 28, 16, 11, 21,\n",
       "          15, 28],\n",
       "         [11, 11, 27, 14, 13, 20, 21, 13, 21, 16, 17, 29, 23, 13, 16, 27, 20, 21,\n",
       "          18, 14]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_edges = []\n",
    "for i, n in enumerate(nums):\n",
    "    edges = torch.randint(low=0, high=n, size=(2, n))\n",
    "    if i > 0:\n",
    "        edges += nums[i - 1]\n",
    "    all_edges.append(edges)\n",
    "all_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ade2b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "offsets = torch.cat([\n",
    "    torch.tensor([0]), \n",
    "    torch.cumsum(nums, dim=0)[:-1]\n",
    "])\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d7586de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9b27d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = [\n",
    "    torch.randint(low=0, high=n, size=(2, n)) + offset\n",
    "    for n, offset in zip(nums, offsets)\n",
    "]\n",
    "E = torch.concat(all_edges, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab0a207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G[indices].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ed34090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 0\n",
    "# indices == b\n",
    "G[indices == b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "be871557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, tensor([10, 20]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nums is verts per graph\n",
    "vpg = nums\n",
    "G.size(0), vpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "daee4b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
       "         28, 29]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting and indexing on a contiguous range is faster than using boolean masks\n",
    "torch.split(torch.arange(G.size(0)), vpg.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40808a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]), tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "all_joints = []\n",
    "for b in range(len(graphs)):\n",
    "    mask = (indices == b)\n",
    "    verts = G[mask]\n",
    "    all_joints.append(verts)\n",
    "print(all_joints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "828f9c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/ModelResource_RigNetv1_preproccessed/mesh_graphs/val.pkl'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import VAL_FILE_PATH, RigNetDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "VAL_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aac86ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vertices': tensor([[-0.1510,  0.2746, -0.0119],\n",
       "         [-0.1707,  0.2635, -0.0522],\n",
       "         [-0.1711,  0.2387, -0.0084],\n",
       "         ...,\n",
       "         [ 0.0686,  0.3920, -0.0187],\n",
       "         [ 0.0619,  0.4156, -0.0122],\n",
       "         [ 0.0721,  0.4075, -0.0188]]),\n",
       " 'num_faces': 3920,\n",
       " 'one_ring': tensor([[   0,  576,    0,  ..., 1493,  357, 1493],\n",
       "         [ 358, 1493, 1491,  ..., 2105, 2106, 2106]]),\n",
       " 'centroid': array([-4.67432633e-05,  4.85459646e-01, -1.37504095e-02]),\n",
       " 'geodesic': tensor([[   0,    0,    0,  ..., 1491, 1486, 1491],\n",
       "         [1490, 1491,  356,  ..., 2102, 2105,  570]]),\n",
       " 'joints': tensor([[ 4.6743e-05,  7.7347e-02,  9.1861e-03],\n",
       "         [ 4.6743e-05,  3.4989e-02,  9.0736e-03],\n",
       "         [ 4.6743e-05,  1.5142e-01,  9.4437e-03],\n",
       "         [ 5.9097e-02, -4.7390e-02,  6.9835e-03],\n",
       "         [-5.8958e-02, -4.7382e-02,  6.9431e-03],\n",
       "         [ 5.2238e-02,  2.5606e-01, -3.6187e-03],\n",
       "         [ 4.6743e-05,  3.4177e-01, -1.1409e-02],\n",
       "         [-5.2113e-02,  2.5606e-01, -3.6187e-03],\n",
       "         [ 5.8834e-02, -2.2482e-01,  1.2228e-03],\n",
       "         [-5.8713e-02, -2.2483e-01,  1.1459e-03],\n",
       "         [ 9.1315e-02,  2.8106e-01, -1.8844e-02],\n",
       "         [-9.1642e-02,  2.8110e-01, -1.8860e-02],\n",
       "         [ 5.8914e-02, -4.3016e-01, -5.9338e-03],\n",
       "         [-5.8832e-02, -4.3019e-01, -6.0530e-03],\n",
       "         [ 2.0893e-01,  2.8079e-01, -1.7807e-02],\n",
       "         [-2.0927e-01,  2.8082e-01, -1.7851e-02],\n",
       "         [ 3.4086e-01,  2.8059e-01, -9.3659e-03],\n",
       "         [-3.4135e-01,  2.8061e-01, -9.3159e-03]]),\n",
       " 'attn_mask': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " 'mesh_index': 9476}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = RigNetDataset(VAL_FILE_PATH, 2, seed=42)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3faa6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch: list[dict]):\n",
    "\n",
    "    verts_list = [b['vertices'] for b in batch]\n",
    "    topo_list = [b['one_ring']  for b in batch]\n",
    "    geodesic_list = [b['geodesic']   for b in batch]\n",
    "\n",
    "    # No need to concatenate these\n",
    "    # they are only used after the batched graph is processed and unbatched\n",
    "    attn_mask_list = [b['attn_mask'] for b in batch]\n",
    "    joints_list = [b['joints'] for b in batch]\n",
    "\n",
    "    verts_per_graph = torch.tensor([verts.size(0) for verts in verts_list])\n",
    "    \n",
    "    # Tensor of all vertices in batch\n",
    "    V = torch.concat(verts_list)\n",
    "\n",
    "    # Vertex-Graph Mapping (maps each vertex to its graph)\n",
    "    graph_idxs = torch.arange(len(verts_per_graph))\n",
    "    vertex_graph_indices = graph_idxs.repeat_interleave(verts_per_graph)\n",
    "\n",
    "    # Edge Index Offsets\n",
    "    # Each edge is represented by a pair of vertex indices\n",
    "    # Edge indices of each graph must be offset by the number of vertices that came before\n",
    "    # The offset of the first graph is zero,\n",
    "    # second graph is len(G1_vertices), third is len(G1_verts) + len(G2_verts), and so on...\n",
    "    offsets = torch.cat([\n",
    "        torch.tensor([0]), \n",
    "        torch.cumsum(verts_per_graph, dim=0)[:-1]\n",
    "    ])\n",
    "\n",
    "    topo_offset_list = []\n",
    "    geo_offset_list = []\n",
    "    for topo_b, geo_b, offset in zip(topo_list, geodesic_list, offsets):\n",
    "        topo_offset_list.append(topo_b + offset)\n",
    "        geo_offset_list.append(geo_b + offset)\n",
    "\n",
    "    E_topo = torch.concat(topo_offset_list, dim=1)\n",
    "    E_geo = torch.concat(geo_offset_list, dim=1)\n",
    "\n",
    "    return {\n",
    "        \"vertices\": V,\n",
    "        \"one_ring\": E_topo,\n",
    "        \"geodesic\": E_geo,\n",
    "        \"graph_idxs\": vertex_graph_indices, # for testing\n",
    "        \"vertices_per_graph\": verts_per_graph,\n",
    "        \"attn_mask_list\": attn_mask_list,\n",
    "        \"joints_list\": joints_list \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c9bd087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ce2ba1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = dataset[0]\n",
    "G2 = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "470dc6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14087"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G1['one_ring'].size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "602c837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True,  True,  True])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_mask = torch.zeros(G1['one_ring'].size(1) + G2['one_ring'].size(1), dtype=torch.long)\n",
    "edge_mask[G1['one_ring'].size(1):] = 1\n",
    "edge_mask = edge_mask == 1\n",
    "edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3d9d85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very basic test\n",
    "for b in dl:\n",
    "    mask = b['graph_idxs'] == 1\n",
    "    verts_g2 = b['vertices'][mask]\n",
    "    # print(b['vertices_per_graph'][0])\n",
    "    # print(b['one_ring'][:, edge_mask].shape, b['vertices_per_graph'][0].shape)\n",
    "    edges_g2 = b['one_ring'][:, edge_mask] - b['vertices_per_graph'][0]\n",
    "    assert torch.all(torch.eq(G2['vertices'], verts_g2))\n",
    "    assert torch.all(torch.eq(G2['one_ring'], edges_g2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7119cd8d",
   "metadata": {},
   "source": [
    "### Rewritten jointnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ce1c6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import JointFeatureNet, MeanShiftClusterer\n",
    "\n",
    "class JointNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 edge_dropout=15,\n",
    "                 initial_h=0.05,\n",
    "                 train_iters=10,\n",
    "                 infer_iters=50):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = JointFeatureNet(edge_dropout=edge_dropout)\n",
    "        self.clustering_head = MeanShiftClusterer(\n",
    "            initial_h=initial_h,\n",
    "            train_iters=train_iters,\n",
    "            infer_iters=infer_iters\n",
    "        )\n",
    "\n",
    "    def forward(self, G: dict):\n",
    "        \"\"\"\n",
    "        Run joint prediction on either a single graph or a batch of graphs.\n",
    "\n",
    "        Args:\n",
    "            G (dict): Graph data, must contain:\n",
    "                - \"vertices\": Tensor of shape [N_total, 3]\n",
    "                - \"one_ring\": LongTensor of shape [2, E_topo_total]\n",
    "                - \"geodesic\": LongTensor of shape [2, E_geo_total]\n",
    "            Optionally:\n",
    "                - \"vertices_per_graph\": 1D Tensor of ints of length N_total\n",
    "                  If present, enables batched mode; otherwise, treats input as a single graph.\n",
    "\n",
    "        Returns:\n",
    "            List[Tensor]: A list of length M (number of graphs).\n",
    "                Each entry is a Tensor of shape [K_i, 3], the predicted joint locations\n",
    "                for graph i. In unbatched mode, returns a single-element list.\n",
    "        \"\"\"\n",
    "        verts = G[\"vertices\"]\n",
    "        E_topo = G[\"one_ring\"]\n",
    "        E_geo = G[\"geodesic\"]\n",
    "\n",
    "        q, attn = self.feature_extractor(verts, E_topo, E_geo)\n",
    "\n",
    "        # Determine batching: if vertices_per_graph is provided, split accordingly.\n",
    "        vpg = G.get(\"vertices_per_graph\", None)\n",
    "        if vpg is None:\n",
    "            # Unbatched: single graph\n",
    "            return [self.clustering_head(q, attn)]\n",
    "\n",
    "        # Batched: split both q and attn by the given vertex counts\n",
    "        # Splitting and indexing on a contigutous range is faster than using boolean masks\n",
    "        splits = torch.split(torch.arange(verts.size(0)), vpg.tolist())\n",
    "        outs = []\n",
    "        for idxs in splits:\n",
    "            q_b = q[idxs]\n",
    "            attn_b = attn[idxs]\n",
    "            outs.append(self.clustering_head(q_b, attn_b))\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "38b8398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RigNetDataset(VAL_FILE_PATH, 2, seed=42)\n",
    "dl = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6b7ed2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.0151,  0.4341,  0.0787],\n",
      "        [ 0.0152, -0.3700,  0.0790],\n",
      "        [ 0.0153, -0.0285,  0.0653],\n",
      "        [-0.3040,  0.3368,  0.0599],\n",
      "        [ 0.3353,  0.3375,  0.0587]], grad_fn=<StackBackward0>), tensor([[ 0.0133,  0.2772,  0.1303],\n",
      "        [ 0.0145, -0.2822,  0.0752],\n",
      "        [-0.1496, -0.0361,  0.0641],\n",
      "        [ 0.1858, -0.0378,  0.0625]], grad_fn=<StackBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "net = JointNet(initial_h=0.2)\n",
    "for batch in dl: \n",
    "    print(net(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e7d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-venv-3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

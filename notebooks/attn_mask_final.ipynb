{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2863684",
   "metadata": {},
   "source": [
    "### Constructing Per-Pixel Binary Attention Masks from Joint and Bone Information\n",
    "\n",
    "The RigNet paper finds that pre-training the attention modules weights with a cross-entropy loss function with a per-vertex attention mask can improve performance. In this notebook, we construct these masks.\n",
    "\n",
    "- Cast K rays from the joint in the direction of the plane orthogonal to the bone centered at the joint (K=14)\n",
    "- Perform triangle-ray intersection and gather vertices closest to intersection points.\n",
    "    - If <6 vertices found, just to kNN centered at the joint with k=6\n",
    "    - If triangle-ray intersection fails, do a \"nearby triangle\" search \n",
    "        - We need this because there ARE rare instances where we rays won't intersect with triangles. This ensures that there at least some training signal retained for each joint\n",
    "- Find the 20th percentile distance of vertices. Multiply this distance by 2. This distance is threshold for retaining points.\n",
    "\n",
    "Notes: \n",
    "- RigNet decimates meshes to 3k verts before doing this. We don't do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578e3152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39f65532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "import trimesh\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm import tqdm\n",
    "from mesh_utils import load_and_preprocess_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee5bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../data/ModelResource_RigNetv1_preproccessed\"\n",
    "obj_folder = f'{data_root}/obj'\n",
    "rig_folder = f'{data_root}/rig_info'\n",
    "attn_mask_folder = f'{data_root}/attn_masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfd39d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/ModelResource_RigNetv1_preproccessed/train_final.txt',\n",
       " '../data/ModelResource_RigNetv1_preproccessed/test_final.txt',\n",
       " '../data/ModelResource_RigNetv1_preproccessed/val_final.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_idx_files = glob.glob(os.path.join(data_root, '*_final.txt'))\n",
    "mesh_idx_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bd39f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2703"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_idxs = []\n",
    "for fpath in mesh_idx_files:\n",
    "    with open(fpath, 'r+') as f:\n",
    "        mesh_idxs.extend(list(map(int, f.read().splitlines())))\n",
    "\n",
    "len(mesh_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e518c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_path_from_idx(idx: int):\n",
    "    return os.path.join(obj_folder, f\"{idx}.obj\")\n",
    "\n",
    "def get_rig_path_from_idx(idx: int):\n",
    "    return os.path.join(rig_folder, f\"{idx}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753e6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rig(rig_path: str, centroid, mesh_idx):\n",
    "    # extraxt join locations\n",
    "    # disregard bone info. Only want joint locations\n",
    "\n",
    "    # file structure:\n",
    "    # joint name x y z\n",
    "    # root name\n",
    "    # skin name1 weight1 name2 weight2 ...\n",
    "    # hier name1 name2\n",
    "\n",
    "    # Will assume this rigid order\n",
    "\n",
    "    jointname2idx = {}\n",
    "    joints = []\n",
    "    bones = []\n",
    "    root_idx = \"\"\n",
    "    with open(rig_path, \"r\") as f:\n",
    "        tokens = f.readline().split()\n",
    "        while(tokens[0] == \"joints\"):\n",
    "            name = tokens[1]\n",
    "            loc = list(map(float, tokens[2:]))\n",
    "\n",
    "            # name to index mapping\n",
    "            next_idx = len(joints)\n",
    "            jointname2idx[name] = next_idx\n",
    "            joints.append(loc)\n",
    "            tokens = f.readline().split()\n",
    "        \n",
    "        # root\n",
    "        root_idx = jointname2idx[tokens[1]]\n",
    "\n",
    "        # Skip skin info\n",
    "        while tokens[0] != \"hier\":\n",
    "            tokens = f.readline().split()\n",
    "        \n",
    "        # Hier info\n",
    "        while tokens:\n",
    "            try:\n",
    "                b1 = jointname2idx[tokens[1]]\n",
    "                b2 = jointname2idx[tokens[2]]\n",
    "                bones.append([b1, b2])\n",
    "            except:\n",
    "                print(f\"Warning: bone ({b1}->{b2}) invalid in mesh {mesh_idx}, skipping bone.\")\n",
    "\n",
    "            tokens = f.readline().split()\n",
    "\n",
    "    joints = np.array(joints) - centroid\n",
    "    \n",
    "    return joints, bones, root_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36bbe4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for finding orthonormal plane to v\n",
    "\n",
    "def pick_arbitrary(v):\n",
    "    # pick axis least aligned with v\n",
    "    abs_v = np.abs(v)\n",
    "\n",
    "    # If the x-component is the smallest, pick the x-axis\n",
    "    if abs_v[0] <= abs_v[1] and abs_v[0] <= abs_v[2]:\n",
    "        return np.array([1.0, 0.0, 0.0])\n",
    "    # x-component is not the smallest. Check if y is smaller than z. \n",
    "    elif abs_v[1] <= abs_v[2]:\n",
    "        return np.array([0.0, 1.0, 0.0])\n",
    "    # z-component is the smallest.\n",
    "    else:\n",
    "        return np.array([0.0, 0.0, 1.0])\n",
    "\n",
    "def get_orthonormal_plane(v, eps=1e-8):\n",
    "    # assume v is already unit length\n",
    "    a = pick_arbitrary(v)\n",
    "    # project a on-to v, then remove component along v\n",
    "    u0 = a - np.dot(a, v) * v\n",
    "    # normalize\n",
    "    u0 /= np.linalg.norm(u0) + eps\n",
    "    # second orthonormal vector\n",
    "    w = np.cross(v, u0)\n",
    "    w /= np.linalg.norm(w) + eps\n",
    "    return u0, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9960105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_rays(joints, bones, K=14):\n",
    "    \"\"\"\n",
    "    joints: list of (x,y,z) arrays, shape [J,3]\n",
    "    bones: list of (parent_idx, child_idx) pairs\n",
    "    K: number of rays per bone-end\n",
    "    \n",
    "    Returns:\n",
    "      origins: np.ndarray [2*K*len(bones), 3]\n",
    "      dirs: np.ndarray [2*K*len(bones), 3]\n",
    "    \"\"\"\n",
    "    origins_list = []\n",
    "    dirs_list = []\n",
    "    joint_idx_list = []\n",
    "    \n",
    "    for p_idx, c_idx in bones:\n",
    "        p_pos = np.array(joints[p_idx])\n",
    "        c_pos = np.array(joints[c_idx])\n",
    "        \n",
    "        # bone direction\n",
    "        v = c_pos - p_pos\n",
    "        v = v / (np.linalg.norm(v) + 1e-10)\n",
    "        \n",
    "        # orthonormal plane basis\n",
    "        u0, w = get_orthonormal_plane(v)\n",
    "        \n",
    "        # sample K angles around the circle\n",
    "        thetas = np.linspace(0, 2*np.pi, K, endpoint=False)\n",
    "\n",
    "        # [K, 3]\n",
    "        dirs_k = np.stack([np.cos(t) * u0 + np.sin(t) * w for t in thetas], axis=0)\n",
    "        dirs_k /= (np.linalg.norm(dirs_k, axis=1, keepdims=True) + 1e-10)\n",
    "        \n",
    "        # create 2 origins (parent & child), each repeated K times\n",
    "        bone_origins = np.vstack([p_pos, c_pos]) # [2,3]\n",
    "        origin_2K = np.repeat(bone_origins, K, axis=0) # [2*K,3]\n",
    "\n",
    "        # joint indices \n",
    "        joint_idxs = np.vstack([p_idx, c_idx])\n",
    "        joints_2K = np.repeat(joint_idxs, K, axis=0)\n",
    "        \n",
    "        # tile dirs twice to match origins\n",
    "        dirs_2K = np.tile(dirs_k, (2, 1)) # [2*K,3]\n",
    "        \n",
    "        origins_list.append(origin_2K)\n",
    "        dirs_list.append(dirs_2K)\n",
    "        joint_idx_list.append(joints_2K)\n",
    "    \n",
    "    # concatenate all bones so we can shoot all rays from every joint together\n",
    "    origins = np.concatenate(origins_list, axis=0)\n",
    "    dirs = np.concatenate(dirs_list, axis=0)\n",
    "    joint_idxs = np.concatenate(joint_idx_list, axis=0)\n",
    "    \n",
    "    return origins, dirs, joint_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4e2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shoot_rays(mesh, origins, dirs, mesh_idx):\n",
    "    intersector = trimesh.ray.ray_triangle.RayMeshIntersector(mesh)\n",
    "    \n",
    "    try:\n",
    "        locs, ray_ids, tri_ids = intersector.intersects_location(origins, dirs)\n",
    "    except Exception as e:\n",
    "        print(f\"Mesh {mesh_idx} ray-intersect failed: {e}; skipping this mesh.\")\n",
    "        return None\n",
    "\n",
    "    hits_by_ray = defaultdict(list)\n",
    "    tris_by_ray = defaultdict(list)\n",
    "\n",
    "    # iterate over every intersection\n",
    "    for pt, r, t in zip(locs, ray_ids, tri_ids):\n",
    "        hits_by_ray[r].append(pt)\n",
    "        tris_by_ray[r].append(t)\n",
    "    \n",
    "    selected_hits = []\n",
    "    # list of tuple[ray_idx, point, triangle, distance from origin]\n",
    "\n",
    "    for r in range(origins.shape[0]):\n",
    "        hits = hits_by_ray.get(r, [])\n",
    "        tris = tris_by_ray.get(r, [])\n",
    "\n",
    "        if hits:\n",
    "            pts = np.stack(hits, axis=0) # [m, 3]\n",
    "            dists = np.linalg.norm(pts - origins[r], axis=1) # origins[r] broadcasted\n",
    "            k = np.argmin(dists) # get closest point\n",
    "        \n",
    "            selected_hits.append((r, pts[k], tris[k], dists[k]))\n",
    "        else:\n",
    "\n",
    "            # Fallback: get faces near the origin\n",
    "            # Index origins with newaxis indexing \n",
    "            close_tris = trimesh.proximity.nearby_faces(mesh, origins[r][None, :])\n",
    "\n",
    "            # get vertices from triangle indices\n",
    "            vs = mesh.faces[close_tris].flatten()\n",
    "\n",
    "            # Use np.asarray to index mesh.vertices with an array (vs)\n",
    "            fallback_pts = np.asarray(mesh.vertices)[vs]\n",
    "            \n",
    "            # record all fallback_pts \n",
    "            for pt in fallback_pts:\n",
    "                selected_hits.append((r, pt, None, None))\n",
    "    \n",
    "    return selected_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1aff5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_hits_by_joint(selected_hits, ray_joint_idxs):\n",
    "\n",
    "    hits_by_joint = defaultdict(list)\n",
    "\n",
    "    for r, pt, *_ in selected_hits:\n",
    "        # which joint generated ray r\n",
    "        j = ray_joint_idxs[r][0] \n",
    "        hits_by_joint[j].append(pt)\n",
    "\n",
    "    # inspect how many hits each joint got\n",
    "    # for j, pts in hits_by_joint.items():\n",
    "    #     print(f\"Joint {j} has {len(pts)} hit points\")\n",
    "    \n",
    "    return hits_by_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f2e4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hits(hits_by_joint, joints):\n",
    "    filtered_pts   = []\n",
    "    filtered_jidxs = []\n",
    "\n",
    "    for j, pts in hits_by_joint.items():\n",
    "        if len(pts) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Stack to (M_j, 3)\n",
    "        pts_arr = np.stack(pts, axis=0)\n",
    "        \n",
    "        # Joint position:\n",
    "        joint_pos = np.array(joints[j])[None, :] # shape (1,3)\n",
    "        \n",
    "        # distances of each hit pt to joint j\n",
    "        dists = np.linalg.norm(pts_arr - joint_pos, axis=1)  # shape (M_j,)\n",
    "        \n",
    "        # 20th percentile\n",
    "        p20 = np.percentile(dists, 20)\n",
    "        \n",
    "        # threshold = 2 * p20\n",
    "        keep_mask = (dists < 2 * p20)\n",
    "        \n",
    "        # collect filtered points\n",
    "        kept_pts = pts_arr[keep_mask]\n",
    "        filtered_pts.append(kept_pts)\n",
    "        \n",
    "        # record joint index for each kept point\n",
    "        filtered_jidxs.append(np.full(len(kept_pts), j, dtype=int))\n",
    "\n",
    "    # Flatten lists into arrays\n",
    "    if filtered_pts:\n",
    "        hit_pts = np.concatenate(filtered_pts, axis=0) # (P,3)\n",
    "        hit_joints = np.concatenate(filtered_jidxs, axis=0) # (P,)\n",
    "    else:\n",
    "        # In case filtered pts is empty\n",
    "        hit_pts = np.zeros((0,3), dtype=float)\n",
    "        hit_joints = np.zeros((0,), dtype=int)\n",
    "\n",
    "    # print(f\"After filtering: {hit_pts.shape[0]} total hit-points across {len(hits_by_joint)} joints\")\n",
    "\n",
    "    return hit_pts, hit_joints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb61ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attention_mask(vtx_ori, hit_pts, radius=0.02):\n",
    "    \"\"\"\n",
    "    vtx_ori : (V,3) array of original mesh vertices\n",
    "    hit_pts : (P,3) array of filtered surface hits\n",
    "    radius   : float radius threshold in mesh units\n",
    "    \n",
    "    Returns:\n",
    "      attn_mask : (V,) boolean array\n",
    "    \"\"\"\n",
    "    V = vtx_ori.shape[0]\n",
    "    attn_mask = np.zeros(V, dtype=bool)\n",
    "    \n",
    "    # build KD-tree on vertices for faster indexing\n",
    "    tree = cKDTree(vtx_ori)\n",
    "    \n",
    "    # for each hit point, find all vertices within radius\n",
    "    # this returns a list of lists; we can flatten it\n",
    "    neighbors = tree.query_ball_point(hit_pts, r=radius)\n",
    "    neighbors = np.unique(np.concatenate(neighbors)).astype('int')\n",
    "    attn_mask[neighbors] = True\n",
    "    \n",
    "    return attn_mask, vtx_ori[neighbors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ef2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attn_mask(mesh_idx: int):\n",
    "    \n",
    "    obj_path = get_obj_path_from_idx(mesh_idx)\n",
    "    rig_path = get_rig_path_from_idx(mesh_idx)\n",
    "    attn_path = f\"{attn_mask_folder}/{mesh_idx}.txt\"\n",
    "\n",
    "    mesh, centroid = load_and_preprocess_mesh(obj_path,\n",
    "                                              min_verts=1000,\n",
    "                                              min_tris=1000,\n",
    "                                              max_tris=8000)\n",
    "\n",
    "    verts = np.asarray(mesh.vertices)\n",
    "    \n",
    "    joints, bones, root_idx = parse_rig(rig_path, centroid, mesh_idx)\n",
    "    origins, dirs, ray_joint_idxs = form_rays(joints, bones, K=14)\n",
    "    hits = shoot_rays(mesh, origins, dirs, mesh_idx)\n",
    "\n",
    "    if hits is None:\n",
    "        print(f\"Skipping Mesh {mesh_idx}\")\n",
    "        return\n",
    "\n",
    "    hits_by_joint = collect_hits_by_joint(hits, ray_joint_idxs)\n",
    "\n",
    "    hit_pts, hit_joints = filter_hits(hits_by_joint, joints)\n",
    "    attn_mask, marked_verts = build_attention_mask(verts, hit_pts, radius=0.02)\n",
    "    # print(f\"{attn_mask.sum()} / {len(attn_mask)} vertices marked as attention.\")\n",
    "\n",
    "    assert len(attn_mask) == len(verts)\n",
    "\n",
    "    np.savetxt(attn_path, attn_mask.astype(int), fmt='%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8f3e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2703 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 508/2703 [00:38<02:13, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: bone (7->20) invalid in mesh 14428, skipping bone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2342/2703 [02:52<00:25, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: bone (0->12) invalid in mesh 18366, skipping bone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2703/2703 [03:15<00:00, 13.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(mesh_idxs):\n",
    "    create_attn_mask(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-venv-3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1176efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "155a3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f02f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_scatter import scatter_max\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mean_shift_clustering import mean_shift_clustering, mode_extraction\n",
    "from models import JointFeatureNet, GMEdgeConv, GMEdgeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1024c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RigNetDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "\n",
    "        with open(file_path, 'rb') as f:\n",
    "            self.examples = pickle.load(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        G = self.examples[index]\n",
    "\n",
    "\n",
    "        G['vertices'] = torch.FloatTensor(G['vertices'])\n",
    "        G['one_ring'] = torch.LongTensor(G['one_ring'])\n",
    "        G['geodesic'] = torch.LongTensor(G['geodesic'])\n",
    "        G['attn_mask'] = torch.FloatTensor(G['attn_mask'])\n",
    "\n",
    "        return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd2f617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use val and test sets for testing\n",
    "train_path = '../data/ModelResource_RigNetv1_preproccessed/mesh_graphs/val.pkl'\n",
    "val_path = '../data/ModelResource_RigNetv1_preproccessed/mesh_graphs/test.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa108a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = RigNetDataset(train_path)\n",
    "val_ds = RigNetDataset(val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17fe052",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e1a883ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model: torch.nn.Module,\n",
    "    dataset,\n",
    "    loss_fn: torch.nn.Module,\n",
    "    device: str = \"cpu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute average loss over `dataset` without gradient updates.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            G = dataset[i]\n",
    "            \n",
    "            verts = G['vertices']\n",
    "            one_ring = G['one_ring']\n",
    "            geodesic = G['geodesic']\n",
    "            attn_mask = G['attn_mask']\n",
    "            \n",
    "            logits = model(verts, one_ring, geodesic).view(-1)\n",
    "            loss = loss_fn(logits, attn_mask)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11e0af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_ds,\n",
    "    val_ds = None,\n",
    "    epochs: int = 10,\n",
    "    device: str = \"cpu\"\n",
    "):\n",
    "\n",
    "    model.to(device)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses   = []\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i in tqdm(range(len(train_ds)), desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "            G = train_ds[i]\n",
    "            \n",
    "            # move data to device\n",
    "            verts = G['vertices']\n",
    "            one_ring = G['one_ring']\n",
    "            geodesic = G['geodesic']\n",
    "            attn_mask = G['attn_mask']\n",
    "            \n",
    "            # forward\n",
    "            logits = model(verts, one_ring, geodesic)\n",
    "            logits = logits.view(-1)\n",
    "            \n",
    "            loss = loss_fn(logits, attn_mask)\n",
    "            \n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_train = running_loss / len(train_ds)\n",
    "        train_losses.append(avg_train)\n",
    "        \n",
    "        # optional validation\n",
    "        if val_ds is not None:\n",
    "            avg_val = validate(model, val_ds, loss_fn, device)\n",
    "            val_losses.append(avg_val)\n",
    "            print(f\"Epoch {epoch}: train loss = {avg_train:.4e}, val loss = {avg_val:.4e}\")\n",
    "\n",
    "            # plot\n",
    "            plt.figure()\n",
    "            plt.semilogy(range(1, epoch+1), train_losses, label=\"train\")\n",
    "            if val_ds is not None:\n",
    "                plt.semilogy(range(1, epoch+1), val_losses, label=\"val\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Loss (BCEWithLogits)\")\n",
    "            plt.title(\"Attention Head Training Loss\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print(f\"Epoch {epoch}: train loss = {avg_train:.4e}\")\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e674c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jointnet = JointFeatureNet(is_training=True)\n",
    "attn_module = jointnet.attn_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c80383ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_jointnet = JointNet(is_training=True)\n",
    "untrained_attn_module = untrained_jointnet.attn_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f4894",
   "metadata": {},
   "source": [
    "### Pre-training Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f5bcfcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "def visualize_attention_heatmap(verts: np.ndarray,\n",
    "                                edges: np.ndarray,\n",
    "                                attn_pred: np.ndarray,\n",
    "                                attn_gt: np.ndarray = None):\n",
    "\n",
    "    # create wireframe\n",
    "    ls = o3d.geometry.LineSet()\n",
    "    ls.points = o3d.utility.Vector3dVector(verts)\n",
    "    ls.lines  = o3d.utility.Vector2iVector(edges)\n",
    "    ls.colors = o3d.utility.Vector3dVector(np.tile([0.7,0.7,0.7], (len(edges),1)))\n",
    "    \n",
    "    # map predictions to colors\n",
    "    N = attn_pred.shape[0]\n",
    "    rgb = np.zeros((N, 3), dtype=attn_pred.dtype)\n",
    "    rgb[:, 0] = attn_pred.reshape(-1)\n",
    "    \n",
    "    # make a point cloud of vertices colored by pred\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(verts)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(rgb)\n",
    "    \n",
    "    # overlay GT as blue points\n",
    "    geometries = [ls, pcd]\n",
    "    if attn_gt is not None:\n",
    "        gt_idxs = np.nonzero(attn_gt.astype(bool))[0]\n",
    "        if len(gt_idxs) > 0:\n",
    "            gt_pcd = o3d.geometry.PointCloud()\n",
    "            # Index the vertices which have a non-zero mask value\n",
    "            gt_pcd.points = o3d.utility.Vector3dVector(verts[gt_idxs])\n",
    "            gt_colors = np.tile([0.0,0.0,1.0], (len(gt_idxs),1))\n",
    "            gt_pcd.colors = o3d.utility.Vector3dVector(gt_colors)\n",
    "            geometries.append(gt_pcd)\n",
    "    \n",
    "    # render\n",
    "    o3d.visualization.draw_geometries(\n",
    "        geometries,\n",
    "        window_name=\"Attention Heatmap (mesh+pred+gt)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d5cab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = train_ds[0]\n",
    "verts = G['vertices']\n",
    "one_ring = G['one_ring']\n",
    "geodesic = G['geodesic']\n",
    "attn_mask = G['attn_mask']\n",
    "\n",
    "attn_pred = F.sigmoid(untrained_attn_module(verts, one_ring, geodesic))\n",
    "attn_gt = attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ffa2f46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5091],\n",
       "        [0.5091],\n",
       "        [0.5091],\n",
       "        ...,\n",
       "        [0.5094],\n",
       "        [0.5094],\n",
       "        [0.5093]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "69b9bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is given a ~0.5 probability. \n",
    "visualize_attention_heatmap(verts=verts.detach().numpy(), \n",
    "                           edges=one_ring.reshape(-1, 2).detach().numpy(), \n",
    "                           attn_pred=attn_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9478a2cd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "32b556ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "lr = 1e-4\n",
    "wd = 1e-5\n",
    "optimizer = torch.optim.AdamW(params=attn_module.parameters(), lr=lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "76820126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 270/270 [03:48<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 6.0019e-01, val loss = 5.7137e-01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 270/270 [09:41<00:00,  2.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_losses, val_losses = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, train_ds, val_ds, epochs, device)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# optional validation\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val_ds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     avg_val = \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     val_losses.append(avg_val)\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: train loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, val loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mvalidate\u001b[39m\u001b[34m(model, dataset, loss_fn, device)\u001b[39m\n\u001b[32m     19\u001b[39m geodesic = G[\u001b[33m'\u001b[39m\u001b[33mgeodesic\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     20\u001b[39m attn_mask = G[\u001b[33m'\u001b[39m\u001b[33mattn_mask\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_ring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeodesic\u001b[49m\u001b[43m)\u001b[49m.view(-\u001b[32m1\u001b[39m)\n\u001b[32m     23\u001b[39m loss = loss_fn(logits, attn_mask)\n\u001b[32m     24\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/tamu/csce685-rignet/notebooks/../utils/models.py:135\u001b[39m, in \u001b[36mVertexAttentionModule.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/tamu/csce685-rignet/notebooks/../utils/models.py:103\u001b[39m, in \u001b[36mGMEdgeNet.forward\u001b[39m\u001b[34m(self, verts, one_ring, geodesic)\u001b[39m\n\u001b[32m    101\u001b[39m out64 = \u001b[38;5;28mself\u001b[39m.conv1(verts, one_ring, geodesic)\n\u001b[32m    102\u001b[39m out256 = \u001b[38;5;28mself\u001b[39m.conv2(out64, one_ring, geodesic)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m out512 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout256\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_ring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeodesic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m x832 = torch.cat([out64, out256, out512], dim=\u001b[32m1\u001b[39m)\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Channelwise max: [832]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/tamu/csce685-rignet/notebooks/../utils/models.py:61\u001b[39m, in \u001b[36mGMEdgeConv.forward\u001b[39m\u001b[34m(self, x, edge_index_topo, edge_index_geo)\u001b[39m\n\u001b[32m     59\u001b[39m xj_g = x[j_g]\n\u001b[32m     60\u001b[39m edge_feat_g = torch.cat([xi_g, xj_g - xi_g], dim=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [E_geo, 2*F_in]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m edge_feat_g = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp_geo\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_feat_g\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [E_geo, hidden]\u001b[39;00m\n\u001b[32m     63\u001b[39m geo_pooled, _ = scatter_max(edge_feat_g, i_g, dim=\u001b[32m0\u001b[39m, dim_size=N)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# geo_pooled: [N, hidden]\u001b[39;00m\n\u001b[32m     65\u001b[39m \n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# --- fuse ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/cs/lib/pytorch-venv-3.11.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train(\n",
    "    attn_module, optimizer,\n",
    "    train_ds=train_ds, val_ds=val_ds,\n",
    "    epochs=epochs, device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a10bdc4",
   "metadata": {},
   "source": [
    "### Individual Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ea386bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4238],\n",
       "        [0.4668],\n",
       "        [0.4660],\n",
       "        ...,\n",
       "        [0.2850],\n",
       "        [0.2838],\n",
       "        [0.2828]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = train_ds[0]\n",
    "verts = G['vertices']\n",
    "one_ring = G['one_ring']\n",
    "geodesic = G['geodesic']\n",
    "attn_mask = G['attn_mask']\n",
    "\n",
    "attn_pred = F.sigmoid(attn_module(verts, one_ring, geodesic))\n",
    "attn_gt = attn_mask\n",
    "\n",
    "attn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "38645dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_attention_heatmap(verts=verts.detach().numpy(), \n",
    "                           edges=one_ring.reshape(-1, 2).detach().numpy(), \n",
    "                           attn_pred=attn_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33d449",
   "metadata": {},
   "source": [
    "Unclear if 4-5 epochs just isn't enough, if LR is too high or too low, etc. Need to run some hyperparameter search grids and evaluate with precision, recall, and F1 to see how the model is doing rather than just vibes\n",
    "\n",
    "- Use matplotlib to create colormap from the attention predictions (use a highly contrasting colormap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-venv-3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
